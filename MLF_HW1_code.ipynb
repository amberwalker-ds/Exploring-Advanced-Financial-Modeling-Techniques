{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bse_logo_textminingcourse](https://bse.eu/sites/default/files/bse_logo_small.png)\n",
    "\n",
    "# Machine Learning for Finance - Assignment 1\n",
    "\n",
    "### by Amber Walker and Clarice Mottet\n",
    "### All work was distributed and completed equally.\n",
    "\n",
    "0. **[Part 0: Set Up and Import](#part0)**\n",
    "- **Objective**: Initialize programming environment and data.\n",
    "- **Tasks:**\n",
    "  - Initialize libraries.\n",
    "  - Import data into the programming environment.\n",
    "  - Conduct preprocessing.\n",
    "\n",
    "1. **[Part 1: EWMA Based Variance](#part1)**\n",
    "- **Objective**: Compare two models to calculate EWMA Based Variance\n",
    "- **Tasks:**\n",
    "  - EWMA Equation: Use the equation covered in class to calculate EWMA based variance.\n",
    "  - EWMA Recursion: Use the recursive formula definition to calculate EWMA based variance.\n",
    "  - Compare the two methods to calculate EWMA based variance.\n",
    "\n",
    "2. **[Part 2: Causality Analysis](#part2)**\n",
    "- **Objective**: Conduct causality analysis with multiple lag variables and time frame windows.\n",
    "- **Tasks:**\n",
    "  - task list here\n",
    "\n",
    "3. **[Part 3: Modeling](#part3)**\n",
    "- **Objective**: Create a neural network and a gaussian process regression to model return, price, or direction (up or down).\n",
    "- **Tasks:**\n",
    "  - (I think we should predict a binary outcome of the stock direction goes up or down personally)\n",
    "  - Feature creation: Create multiple types of lag variables for different lag amounts.\n",
    "  - Feature selection: (I'd suggest a good old random forest cause I personally love a random forest feature selection or an XGBoost feature selection).\n",
    "  - Create a neural network, discuss hyper parameter tuning.\n",
    "  - Create a gaussian process, discuss hyper parameter tuning.\n",
    "\n",
    "4. **[Part 4: Further Analysis](#part4)**\n",
    "- **Objective**: Discuss modeling aspects and compare methods.\n",
    "- **Tasks:** \n",
    "  - Create an ARMA model and compare to the neural network and gaussian process.\n",
    "  - Discuss if bootstrapping would aid model performance and efficacy and what modeling would look like with the incorporation of stationary bootstrapping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='part0'>Part 0: Set Up and Import</a>\n",
    "- **Objective**: Initialize programming environment and data.\n",
    "- **Tasks:**\n",
    "  - Initialize libraries.\n",
    "  - Import data into the programming environment.\n",
    "  - Conduct preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "#Paths\n",
    "path_in_ = r'/home/clarice/Documents/VSCode/Term3/ML_Finance/MLF_HW1/inputs/'\n",
    "path_out_ = r'/home/clarice/Documents/VSCode/Term3/ML_Finance/MLF_HW1/outputs/'\n",
    "# path_in_ = r'AMBER'\n",
    "# path_out_ = r'AMBER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>adjusted</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69035.000000</td>\n",
       "      <td>69035.000000</td>\n",
       "      <td>69035.000000</td>\n",
       "      <td>69035.000000</td>\n",
       "      <td>6.903500e+04</td>\n",
       "      <td>69035.000000</td>\n",
       "      <td>70078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11464.128611</td>\n",
       "      <td>11555.368887</td>\n",
       "      <td>11366.426424</td>\n",
       "      <td>11462.595335</td>\n",
       "      <td>4.028610e+08</td>\n",
       "      <td>11462.588664</td>\n",
       "      <td>2009-08-02 18:18:57.361225984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.010000</td>\n",
       "      <td>9.310000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>9.140000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.140000</td>\n",
       "      <td>1999-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1891.545044</td>\n",
       "      <td>1907.417481</td>\n",
       "      <td>1872.669983</td>\n",
       "      <td>1890.239990</td>\n",
       "      <td>8.400000e+03</td>\n",
       "      <td>1890.239990</td>\n",
       "      <td>2004-03-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6737.540039</td>\n",
       "      <td>6785.109863</td>\n",
       "      <td>6682.490234</td>\n",
       "      <td>6733.229980</td>\n",
       "      <td>4.237800e+06</td>\n",
       "      <td>6733.204102</td>\n",
       "      <td>2009-07-21 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11869.479981</td>\n",
       "      <td>11951.899903</td>\n",
       "      <td>11773.080078</td>\n",
       "      <td>11867.850098</td>\n",
       "      <td>1.535236e+08</td>\n",
       "      <td>11867.850098</td>\n",
       "      <td>2014-12-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>119528.000000</td>\n",
       "      <td>119593.000000</td>\n",
       "      <td>118108.000000</td>\n",
       "      <td>119528.000000</td>\n",
       "      <td>1.145623e+10</td>\n",
       "      <td>119528.000000</td>\n",
       "      <td>2020-04-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15447.245090</td>\n",
       "      <td>15581.477219</td>\n",
       "      <td>15309.464143</td>\n",
       "      <td>15448.944086</td>\n",
       "      <td>9.914707e+08</td>\n",
       "      <td>15448.946777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open           high            low          close  \\\n",
       "count   69035.000000   69035.000000   69035.000000   69035.000000   \n",
       "mean    11464.128611   11555.368887   11366.426424   11462.595335   \n",
       "min         9.010000       9.310000       8.560000       9.140000   \n",
       "25%      1891.545044    1907.417481    1872.669983    1890.239990   \n",
       "50%      6737.540039    6785.109863    6682.490234    6733.229980   \n",
       "75%     11869.479981   11951.899903   11773.080078   11867.850098   \n",
       "max    119528.000000  119593.000000  118108.000000  119528.000000   \n",
       "std     15447.245090   15581.477219   15309.464143   15448.944086   \n",
       "\n",
       "             volume       adjusted                           date  \n",
       "count  6.903500e+04   69035.000000                          70078  \n",
       "mean   4.028610e+08   11462.588664  2009-08-02 18:18:57.361225984  \n",
       "min    0.000000e+00       9.140000            1999-01-04 00:00:00  \n",
       "25%    8.400000e+03    1890.239990            2004-03-19 00:00:00  \n",
       "50%    4.237800e+06    6733.204102            2009-07-21 00:00:00  \n",
       "75%    1.535236e+08   11867.850098            2014-12-09 00:00:00  \n",
       "max    1.145623e+10  119528.000000            2020-04-30 00:00:00  \n",
       "std    9.914707e+08   15448.946777                            NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import\n",
    "\n",
    "#using a text file we created from an R file\n",
    "df_market = pd.read_csv(path_in_ + 'WorldMarkets99_20.txt', sep = '|', dtype = str)\n",
    "df_market.columns = df_market.columns.str.lower().str.strip()\n",
    "df_market[['open','high','low','close','volume','adjusted']] = df_market[['open','high','low','close','volume','adjusted']].apply(pd.to_numeric)\n",
    "df_market['date'] = pd.to_datetime(df_market['date'])\n",
    "df_market.sort_values(by = ['market','date'], inplace = True)\n",
    "df_market.reset_index(drop = True, inplace = True)\n",
    "\n",
    "df_market.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_view = df_market[df_market['market']=='BSESN'].copy()\n",
    "df_view.to_excel(path_out_+'view_BSESN.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like missing information above corresponds to bank holidays, I would do a .ffill() grouped by the column 'market' to fill in null values with the previous date's available market close.\n",
    "\n",
    "There are no weekend dates in the data, so I would add in dates that are missing and also do a .ffill() grouped by the column 'market' and also include in the data a one hot encoded field that is 1 for week day and 0 for weekend to account for this preprocessing. I think we're going to want all dates to build a model on.\n",
    "\n",
    ".ffill() is a forward fill so that when you fill in missing information for a date, its filling in the missing information with the last previous day's information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='part1'>Part 1: EWMA Based Variance</a>\n",
    "- **Objective**: Compare two models to calculate EWMA Based Variance\n",
    "- **Tasks:**\n",
    "  - EWMA Equation: Use the equation covered in class to calculate EWMA based variance.\n",
    "  - EWMA Recursion: Use the recursive formula definition to calculate EWMA based variance.\n",
    "  - Compare the two methods to calculate EWMA based variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EWMA Equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EWMA Recusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare equation to recursion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='part2'>Part 2: Causality Analysis</a>\n",
    "- **Objective**: Conduct causality analysis with multiple lag variables and time frame windows.\n",
    "- **Tasks:**\n",
    "  - task list here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Causality analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='part3'>Part 3: Modeling</a>\n",
    "- **Objective**: Create a neural network and a gaussian process regression to model return, price, or direction (up or down).\n",
    "- **Tasks:**\n",
    "  - (I think we should predict a binary outcome of the stock direction goes up or down personally)\n",
    "  - Feature creation: Create multiple types of lag variables for different lag amounts.\n",
    "  - Feature selection: (I'd suggest a good old random forest cause I personally love a random forest feature selection or an XGBoost feature selection).\n",
    "  - Create a neural network, discuss hyper parameter tuning.\n",
    "  - Create a gaussian process, discuss hyper parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='part4'>Part 4: Further Analysis</a>\n",
    "- **Objective**: Discuss modeling aspects and compare methods.\n",
    "- **Tasks:** \n",
    "  - Create an ARMA model and compare to the neural network and gaussian process.\n",
    "  - Discuss if bootstrapping would aid model performance and efficacy and what modeling would look like with the incorporation of stationary bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARMA model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare ARMA model to NN and Gaussian Process Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stationary Bootstrapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling with Stationary Bootstrapping (if necessary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
